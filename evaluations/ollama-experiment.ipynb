{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Using cached datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\neham\\tamu\\research_project_llm\\spring2025\\private-data-blocker\\.venv\\lib\\site-packages (from datasets) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\neham\\tamu\\research_project_llm\\spring2025\\private-data-blocker\\.venv\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Using cached pyarrow-19.0.0-cp311-cp311-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\neham\\tamu\\research_project_llm\\spring2025\\private-data-blocker\\.venv\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\neham\\tamu\\research_project_llm\\spring2025\\private-data-blocker\\.venv\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.5.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
      "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Using cached aiohttp-3.11.11-cp311-cp311-win_amd64.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\neham\\tamu\\research_project_llm\\spring2025\\private-data-blocker\\.venv\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\neham\\tamu\\research_project_llm\\spring2025\\private-data-blocker\\.venv\\lib\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\neham\\tamu\\research_project_llm\\spring2025\\private-data-blocker\\.venv\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\neham\\tamu\\research_project_llm\\spring2025\\private-data-blocker\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets)\n",
      "  Using cached attrs-25.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Using cached frozenlist-1.5.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Using cached multidict-6.1.0-cp311-cp311-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Using cached propcache-0.2.1-cp311-cp311-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Using cached yarl-1.18.3-cp311-cp311-win_amd64.whl.metadata (71 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\neham\\tamu\\research_project_llm\\spring2025\\private-data-blocker\\.venv\\lib\\site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\neham\\tamu\\research_project_llm\\spring2025\\private-data-blocker\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\neham\\tamu\\research_project_llm\\spring2025\\private-data-blocker\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\neham\\tamu\\research_project_llm\\spring2025\\private-data-blocker\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\neham\\tamu\\research_project_llm\\spring2025\\private-data-blocker\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\neham\\tamu\\research_project_llm\\spring2025\\private-data-blocker\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\neham\\tamu\\research_project_llm\\spring2025\\private-data-blocker\\.venv\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Using cached datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "Using cached pandas-2.2.3-cp311-cp311-win_amd64.whl (11.6 MB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Using cached aiohttp-3.11.11-cp311-cp311-win_amd64.whl (442 kB)\n",
      "Using cached multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Using cached pyarrow-19.0.0-cp311-cp311-win_amd64.whl (25.3 MB)\n",
      "Downloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Using cached tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Using cached xxhash-3.5.0-cp311-cp311-win_amd64.whl (30 kB)\n",
      "Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-25.1.0-py3-none-any.whl (63 kB)\n",
      "Using cached frozenlist-1.5.0-cp311-cp311-win_amd64.whl (51 kB)\n",
      "Using cached multidict-6.1.0-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Using cached propcache-0.2.1-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Using cached yarl-1.18.3-cp311-cp311-win_amd64.whl (91 kB)\n",
      "Installing collected packages: pytz, xxhash, tzdata, pyarrow, propcache, multidict, fsspec, frozenlist, dill, attrs, aiohappyeyeballs, yarl, pandas, multiprocess, aiosignal, aiohttp, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.2.0\n",
      "    Uninstalling fsspec-2025.2.0:\n",
      "      Successfully uninstalled fsspec-2025.2.0\n",
      "Successfully installed aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 attrs-25.1.0 datasets-3.2.0 dill-0.3.8 frozenlist-1.5.0 fsspec-2024.9.0 multidict-6.1.0 multiprocess-0.70.16 pandas-2.2.3 propcache-0.2.1 pyarrow-19.0.0 pytz-2025.1 tzdata-2025.1 xxhash-3.5.0 yarl-1.18.3\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets pandas\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\neham\\TAMU\\research_project_llm\\Spring2025\\private-data-blocker\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import json\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the below cell, to change values for the experiment, after changing this run all the cells below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"ai4privacy/pii-masking-200k\"\n",
    "samples = 10\n",
    "\n",
    "#parameters for ollama experiment\n",
    "source_text_file_name = \"source_texts.json\"\n",
    "predicted_labels_file_name = \"predicted_labels.json\"\n",
    "model_name =  \"llama3.2:latest\" #\"qwen2.5:3b\" #\"llama3.2:latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_with_labels_file_name = \"results_with_labels_compared.json\"\n",
    "results_file_name = \"results.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_name):\n",
    "    dataset = load_dataset(dataset_name)\n",
    "    filtered_dataset = dataset.filter(lambda example: example['language'] == 'en')\n",
    "    df = filtered_dataset['train'].to_pandas() \n",
    "    df.head()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = load_data(dataset_name=dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43501"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#length of the dataset\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_dataset(rows, df):\n",
    "    return df.head(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = filtered_dataset(samples, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#length of filtered dataset\n",
    "len(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'value': '10:18 PM', 'start': 30, 'end': 38, 'label': 'TIME'}\n",
      " {'value': 'Human Group Coordinator', 'start': 44, 'end': 67, 'label': 'JOBTITLE'}\n",
      " {'value': 'Cleveland', 'start': 71, 'end': 80, 'label': 'COUNTY'}\n",
      " {'value': 'Emilie_Beatty53@hotmail.com', 'start': 117, 'end': 144, 'label': 'EMAIL'}\n",
      " {'value': '63652332', 'start': 169, 'end': 177, 'label': 'ACCOUNTNUMBER'}\n",
      " {'value': '8824', 'start': 259, 'end': 263, 'label': 'PIN'}\n",
      " {'value': 'Eye color: Brown', 'start': 279, 'end': 295, 'label': 'EYECOLOR'}]\n"
     ]
    }
   ],
   "source": [
    "index = samples-1\n",
    "print(df_filtered.iloc[index]['privacy_mask']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sensitive_data(privacy_mask):\n",
    "    return {item['label']: item['value'] for item in privacy_mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neham\\AppData\\Local\\Temp\\ipykernel_45152\\1344952930.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['sensitive_data_json'] = df_filtered['privacy_mask'].apply(extract_sensitive_data)\n"
     ]
    }
   ],
   "source": [
    "df_filtered['sensitive_data_json'] = df_filtered['privacy_mask'].apply(extract_sensitive_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sensitive_data_json'] = df['privacy_mask'].apply(extract_sensitive_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AGE': '88', 'BUILDINGNUMBER': '5862', 'PASSWORD': 'Y2rWliOhf8Ir'}\n"
     ]
    }
   ],
   "source": [
    "index = samples-1\n",
    "print(df_filtered.iloc[4]['sensitive_data_json'])  #example of the new column generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_source_texts(data, file_name):\n",
    "    source_texts = data['source_text'].tolist()\n",
    "    with open(file_name, \"w\") as json_file:\n",
    "        json.dump(source_texts, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_source_texts(df_filtered, source_text_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'source_texts.json'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_text_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of source texts: 10\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def retrieve_source_texts(file_name):\n",
    "    with open(file_name, \"r\") as json_file:\n",
    "        source_texts = json.load(json_file)\n",
    "    return source_texts\n",
    "\n",
    "def count_source_texts(file_name):\n",
    "    source_texts = retrieve_source_texts(file_name)\n",
    "    return len(source_texts)\n",
    "\n",
    "# Example usage\n",
    "file_name = \"source_texts.json\"\n",
    "source_text_count = count_source_texts(file_name)\n",
    "print(f\"Number of source texts: {source_text_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimenting with Ollama, now run 'evaluation.js' to get the labels from the model (predicted labels by the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processSourceTexts() called\n",
      "getting text - so this is printed  \n",
      "Prompt 0 processing time 121.84786539999999 seconds\n",
      "Prompt 1 processing time 22.276150200000004 seconds\n",
      "Prompt 2 processing time 16.589166800000008 seconds\n",
      "Prompt 3 processing time 12.623969300000025 seconds\n",
      "Prompt 4 processing time 11.368677600000025 seconds\n",
      "Prompt 5 processing time 24.927886800000007 seconds\n",
      "Prompt 6 processing time 14.526170599999983 seconds\n",
      "Prompt 7 processing time 19.131839800000016 seconds\n",
      "Prompt 8 processing time 11.167882500000006 seconds\n",
      "Prompt 9 processing time 14.881147599999997 seconds\n",
      "Prompt processing time for batch = 269.3407566000001\n",
      "Batch 0 to 9 processed and saved successfully.\n",
      "Average time 26.93407566000001\n",
      "All Texts processing time 269.39 seconds\n",
      "All results processed and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "!node evaluation.js {model_name} {source_text_file_name} {predicted_labels_file_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_labels(file_name):\n",
    "    with open(file_name, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)  # Load the entire JSON object\n",
    "\n",
    "    # Extract results and average processing time\n",
    "    raw_results = data.get(\"results\", [])  # Default to empty list if missing\n",
    "    total_time = float(data.get(\"processingTimeSeconds\", 0))  # Convert string to float\n",
    "    average_time_per_prompt = float(data.get(\"averageTimePerPromptSeconds\", 0))\n",
    "\n",
    "    # Convert JSON strings into dictionaries\n",
    "    parsed_results = []\n",
    "    for item in raw_results:\n",
    "        if item is not None:  \n",
    "            try:\n",
    "                parsed_results.append(json.loads(item))\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Invalid JSON detected, storing as empty object: {item}\")\n",
    "                parsed_results.append({})\n",
    "        else:\n",
    "            print(\"Null item found, storing as empty object\")\n",
    "            parsed_results.append({})\n",
    "\n",
    "    return parsed_results, total_time, average_time_per_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'predicted_labels.json'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels, total_time, average_time_per_prompt = get_predicted_labels(predicted_labels_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'device': 'IMEI', 'curriculum': 'Optimization'}, {'username': 'Omer', 'identity document': 'license', 'number': '78B5R2MVFAHJ48500', 'identity document type': 'idcard', 'code': '78B5R2MVFAHJ48500'}, {'name': 'Kattie', 'age': '72', 'gender': 'Intersex', 'birthday': '158centimeters', 'height': '158 centimeters'}, {'name': 'Nancy', 'city': 'Boston', \"'place\": '16356'}, {'child': 'child', 'age': '88', 'zipcode': '5862', 'password': 'Y2rWliOhf8Ir'}, {'name': 'Nancy', 'age': '18', 'city': 'Boston', 'database': 'edaf:fd8f:e1e8:cfec:8bab:1afd:6aad:550c'}, {'gender': 'Trans male', 'database': 'E5_N8G2xWM6D'}, {'place': 'longitude', 'browser': 'Mozilla/5.0 (Macintosh; PPC Mac OS X 10.7.5; rv:12.5) Gecko/20100101 Firefox/12.5.9'}, {'age': '18', 'city': 'Boston'}, {'name': 'Nancy', 'age': '18', 'city': 'Boston'}]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269.39\n"
     ]
    }
   ],
   "source": [
    "print(total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.93\n"
     ]
    }
   ],
   "source": [
    "print(average_time_per_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_labels(data):\n",
    "    return data['sensitive_data_json'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_labels = get_original_labels(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(original_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_comparison = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to calculate accuracy based on matching labels\n",
    "def calculate_accuracy_label_comparison(parsed_data, sensitive_data_json_list):\n",
    "    correct_count = 0\n",
    "    total_count = 0\n",
    "    label_comparison = []\n",
    "    for i, (parsed_item, sensitive_data) in enumerate(zip(parsed_data, sensitive_data_json_list)):\n",
    "        original_sensitive_values = list(sensitive_data.values())\n",
    "        print(\"original values\", original_sensitive_values)\n",
    "\n",
    "        generated_sensitive_values = list(parsed_item.values())  \n",
    "        print(\"generated values\", generated_sensitive_values)\n",
    "        label_comparison.append({\"actual_values\":original_sensitive_values, \"predicted_values\":generated_sensitive_values})\n",
    "\n",
    "        label_correct = 0\n",
    "        for generated_value in generated_sensitive_values:\n",
    "            for original_value in original_sensitive_values:\n",
    "                original_value_lower = original_value.lower()\n",
    "                generated_value_lower = generated_value.lower()\n",
    "                # original_value_lower = original_value_lower.replace(\" \",\"\")\n",
    "                if original_value_lower in generated_value_lower or generated_value_lower in original_value_lower:\n",
    "                    label_correct +=1\n",
    "        if label_correct>0:\n",
    "            if label_correct>len(original_sensitive_values):\n",
    "                label_correct = len(original_sensitive_values) #added this for experiment with HF model (generated sensitive values are split)\n",
    "            print(f\"number of correct labels {label_correct}/{len(original_sensitive_values)}\")\n",
    "        else:\n",
    "            print(\"0 correct labels found\")\n",
    "            \n",
    "        correct_count+=label_correct\n",
    "        total_count += len(original_sensitive_values)\n",
    "        print()\n",
    "\n",
    "    accuracy = correct_count / total_count if total_count > 0 else 0\n",
    "    return accuracy, label_comparison\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'device': 'IMEI', 'curriculum': 'Optimization'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original values ['06-184755-866851-3', 'Optimization']\n",
      "generated values ['IMEI', 'Optimization']\n",
      "number of correct labels 1/2\n",
      "\n",
      "original values ['Omer', '78B5R2MVFAHJ48500']\n",
      "generated values ['Omer', 'license', '78B5R2MVFAHJ48500', 'idcard', '78B5R2MVFAHJ48500']\n",
      "number of correct labels 2/2\n",
      "\n",
      "original values ['Kattie', '72', 'Intersex person', '158centimeters']\n",
      "generated values ['Kattie', '72', 'Intersex', '158centimeters', '158 centimeters']\n",
      "number of correct labels 4/4\n",
      "\n",
      "original values ['16356', '5890724654311332']\n",
      "generated values ['Nancy', 'Boston', '16356']\n",
      "number of correct labels 1/2\n",
      "\n",
      "original values ['88', '5862', 'Y2rWliOhf8Ir']\n",
      "generated values ['child', '88', '5862', 'Y2rWliOhf8Ir']\n",
      "number of correct labels 3/3\n",
      "\n",
      "original values ['29/12/1957', 'edaf:fd8f:e1e8:cfec:8bab:1afd:6aad:550c']\n",
      "generated values ['Nancy', '18', 'Boston', 'edaf:fd8f:e1e8:cfec:8bab:1afd:6aad:550c']\n",
      "number of correct labels 1/2\n",
      "\n",
      "original values ['Trans male', 'E5_N8G2xWM6D']\n",
      "generated values ['Trans male', 'E5_N8G2xWM6D']\n",
      "number of correct labels 2/2\n",
      "\n",
      "original values ['[-71.6702,-107.6572]', 'Mozilla/5.0 (Macintosh; PPC Mac OS X 10.7.5; rv:12.5) Gecko/20100101 Firefox/12.5.9']\n",
      "generated values ['longitude', 'Mozilla/5.0 (Macintosh; PPC Mac OS X 10.7.5; rv:12.5) Gecko/20100101 Firefox/12.5.9']\n",
      "number of correct labels 1/2\n",
      "\n",
      "original values ['Carleton', '[-38.9302,113.5422]', 'yZqd7gHyZq91']\n",
      "generated values ['18', 'Boston']\n",
      "0 correct labels found\n",
      "\n",
      "original values ['10:18 PM', 'Human Group Coordinator', 'Cleveland', 'Emilie_Beatty53@hotmail.com', '63652332', '8824', 'Eye color: Brown']\n",
      "generated values ['Nancy', '18', 'Boston']\n",
      "number of correct labels 1/7\n",
      "\n",
      "Accuracy: 55.17%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy measure \n",
    "accuracy, label_comparison= calculate_accuracy_label_comparison(predicted_labels, original_labels)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'actual_values': ['06-184755-866851-3', 'Optimization'], 'predicted_values': ['IMEI', 'Optimization']}, {'actual_values': ['Omer', '78B5R2MVFAHJ48500'], 'predicted_values': ['Omer', 'license', '78B5R2MVFAHJ48500', 'idcard', '78B5R2MVFAHJ48500']}, {'actual_values': ['Kattie', '72', 'Intersex person', '158centimeters'], 'predicted_values': ['Kattie', '72', 'Intersex', '158centimeters', '158 centimeters']}, {'actual_values': ['16356', '5890724654311332'], 'predicted_values': ['Nancy', 'Boston', '16356']}, {'actual_values': ['88', '5862', 'Y2rWliOhf8Ir'], 'predicted_values': ['child', '88', '5862', 'Y2rWliOhf8Ir']}, {'actual_values': ['29/12/1957', 'edaf:fd8f:e1e8:cfec:8bab:1afd:6aad:550c'], 'predicted_values': ['Nancy', '18', 'Boston', 'edaf:fd8f:e1e8:cfec:8bab:1afd:6aad:550c']}, {'actual_values': ['Trans male', 'E5_N8G2xWM6D'], 'predicted_values': ['Trans male', 'E5_N8G2xWM6D']}, {'actual_values': ['[-71.6702,-107.6572]', 'Mozilla/5.0 (Macintosh; PPC Mac OS X 10.7.5; rv:12.5) Gecko/20100101 Firefox/12.5.9'], 'predicted_values': ['longitude', 'Mozilla/5.0 (Macintosh; PPC Mac OS X 10.7.5; rv:12.5) Gecko/20100101 Firefox/12.5.9']}, {'actual_values': ['Carleton', '[-38.9302,113.5422]', 'yZqd7gHyZq91'], 'predicted_values': ['18', 'Boston']}, {'actual_values': ['10:18 PM', 'Human Group Coordinator', 'Cleveland', 'Emilie_Beatty53@hotmail.com', '63652332', '8824', 'Eye color: Brown'], 'predicted_values': ['Nancy', '18', 'Boston']}]\n"
     ]
    }
   ],
   "source": [
    "print(label_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_results_file(filename):\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'r') as file:\n",
    "            data = json.load(file)\n",
    "    else:\n",
    "        data = []\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_labels = open_results_file(results_with_labels_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_only_results = open_results_file(results_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 55.17, samples = 10, model_name = llama3.2:latest, average_time_per_prompt = 26.93\n"
     ]
    }
   ],
   "source": [
    "print(f\"accuracy = {accuracy * 100:.2f}, samples = {samples}, model_name = {model_name}, average_time_per_prompt = {average_time_per_prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.172413793103445"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_percent = accuracy*100\n",
    "accuracy_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'llama3.2:latest'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_results_with_labels(labelcomparison, accuracy, samples, model_name, per_prompt_time, total_time):\n",
    "    return {\"label comparison\":labelcomparison, \"accuracy\":accuracy, \"number_of_samples\":samples, \"model_name\":model_name, \"average_time_per_prompt\":per_prompt_time, \"total_time\":total_time}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_results(accuracy, samples, model_name, per_prompt_time, totaltime):\n",
    "    return {\"accuracy\":accuracy, \"number_of_samples\":samples, \"model_name\":model_name, \"average_time_per_prompt\":per_prompt_time, \"total_time\":totaltime}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_labels.append(experiment_results_with_labels(label_comparison, accuracy_percent, samples, model_name, average_time_per_prompt, total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_only_results.append(experiment_results(accuracy_percent, samples, model_name, average_time_per_prompt, total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 55.172413793103445,\n",
       " 'number_of_samples': 10,\n",
       " 'model_name': 'llama3.2:latest',\n",
       " 'average_time_per_prompt': 26.93,\n",
       " 'total_time': 269.39}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_results(accuracy=accuracy_percent, samples=samples, model_name=model_name, per_prompt_time=average_time_per_prompt, totaltime=total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_data(data,file_name):\n",
    "    with open(file_name, 'w') as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "    print(\"Experiment results saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment results saved successfully!\n"
     ]
    }
   ],
   "source": [
    "dump_data(data_with_labels, results_with_labels_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment results saved successfully!\n"
     ]
    }
   ],
   "source": [
    "dump_data(data_only_results, results_file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
